{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "845ae6bd-e195-49c4-9fc4-99d9d8b4b2aa",
   "metadata": {},
   "source": [
    "# Getting started with NLP (natural language processing) with Python\n",
    "\n",
    "In this notebook I'm using an NLTK library to perform some basic NLP tasks.\n",
    "**NLTK (natural language toolkit)** is a Python library that comes with built-in functinality to perform the task such as:\n",
    "\n",
    "1. Tokenization\n",
    "2. Stopword removal\n",
    "3. N-Grams\n",
    "4. Stemming\n",
    "5. Part-of-speech\n",
    "6. Word sense disambiguation\n",
    "\n",
    "I'll provide a short explanation of what each task means and an example of its use along with NLTK modules needed to perform the task.\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72397dcb-b314-49da-8fd5-0f501ae3a400",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokenizing text\n",
    "\n",
    "The process of breaking the text down into small pieces - words or sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f10b00c-1bf2-4cca-a878-b3bc1aa30bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/c75d4454-e391-4890-b9d7-5d2bf0a84bec/nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/c75d4454-e391-4890-b9d7-5d2bf0a84bec/nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/c75d4454-e391-4890-b9d7-5d2bf0a84bec/nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/c75d4454-e391-4890-b9d7-5d2bf0a84bec/nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/c75d4454-e391-4890-b9d7-5d2bf0a84bec/nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa22e8-f081-4fe9-b757-ba0012049058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24114176-ee25-4804-bcc4-1d80c0817477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary had a little lamb.', 'Her fleece was white as snow']\n"
     ]
    }
   ],
   "source": [
    "text=\"Mary had a little lamb. Her fleece was white as snow\"\n",
    "\n",
    "# Import functions to break text into words/sentences from nltk.tokenize module\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "sents=sent_tokenize(text)\n",
    "print(sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b4860fb-f7d1-4b30-9e4c-260cbbd92b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mary', 'had', 'a', 'little', 'lamb', '.'], ['Her', 'fleece', 'was', 'white', 'as', 'snow']]\n"
     ]
    }
   ],
   "source": [
    "words = [word_tokenize(sent) for sent in sents]\n",
    "print(words)\n",
    "\n",
    "# Punctuation is treated as an individual token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bfc3d2-8ade-451a-afca-3fc17dca0dd8",
   "metadata": {},
   "source": [
    "## Stopwords removal\n",
    "\n",
    "The process of removing the words that don't hold meaning (such as \"a\", \"was\", \"her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca5ee6f-4902-4d3a-95c8-81887c8e0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "# creating a custom set of stopwords (using a set instead of a list because the order doesn't matter)\n",
    "\n",
    "customStopWords=set(stopwords.words('english')+list(punctuation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dcbff85-f63f-4a5a-afb8-ed2ce37e7298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary', 'little', 'lamb', 'Her', 'fleece', 'white', 'snow']\n"
     ]
    }
   ],
   "source": [
    "wordsWoStopwords=[word for word in word_tokenize(text) if word not in customStopWords]\n",
    "print(wordsWoStopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c12ddd7-d794-4b4f-88cc-97dfa6cd2a5a",
   "metadata": {},
   "source": [
    "## Identifying N-grams\n",
    "\n",
    "N-grams are combinations of words that occur consecutively. Usually used to find bigrams (pairs of words, eg: \"New York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98aec7f8-1ab5-483c-bcad-1aeb8a64a5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Her', 'fleece'), 1),\n",
       " (('Mary', 'little'), 1),\n",
       " (('fleece', 'white'), 1),\n",
       " (('lamb', 'Her'), 1),\n",
       " (('little', 'lamb'), 1),\n",
       " (('white', 'snow'), 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "# constructs bigrams from the list of words, BigramCollocationFinder is a built-in class\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(wordsWoStopwords)\n",
    "\n",
    "# displays bigrams and their frequencies, if there are more than 1 of a kind - sorts in descending order\n",
    "\n",
    "sorted(finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2d8fd-4876-421d-a966-23a33470569f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1ad157d-6193-4ff0-a474-54b7798d8a6c",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "The process of extracting words's root to treat same word with a different ending as the same word (eg: \"close, closer, closing, closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "130ecc14-0bb3-408e-a757-a7c55d463985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', 'clos', 'on', 'clos', 'night', 'when', 'she', 'was', 'in', 'the', 'mood', 'to', 'clos', '.']\n"
     ]
    }
   ],
   "source": [
    "text2=\"Mary closed on closing night when she was in the mood to close.\"\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "st=LancasterStemmer()\n",
    "stemmedWords = [st.stem(word) for word in word_tokenize(text2)]\n",
    "print(stemmedWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b410e-38a8-474f-bbc1-a9eaee2b1b4c",
   "metadata": {},
   "source": [
    "## Part-of-speech\n",
    "\n",
    "The process of identyfying whether the word is a noun, adjective, verb etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6c7ca6-8023-40e9-b503-d9f26059d114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mary', 'NNP'),\n",
       " ('closed', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('closing', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('when', 'WRB'),\n",
       " ('she', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('mood', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('close', 'VB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos_tag (build-in function to tag a part of speech)\n",
    "\n",
    "nltk.pos_tag(word_tokenize(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4ba1f-7ad0-4aed-ba1b-a914f79d3678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24499422-4828-447c-bc39-5dff28f675c9",
   "metadata": {},
   "source": [
    "## Word sense disambiguation\n",
    "\n",
    "The process of identifying word's meaning based on the context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac6eeb52-228c-4867-98eb-92b0c1443be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bass.n.01') the lowest part of the musical range\n",
      "Synset('bass.n.02') the lowest part in polyphonic music\n",
      "Synset('bass.n.03') an adult male singer with the lowest voice\n",
      "Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n",
      "Synset('freshwater_bass.n.01') any of various North American freshwater fish with lean flesh (especially of the genus Micropterus)\n",
      "Synset('bass.n.06') the lowest adult male singing voice\n",
      "Synset('bass.n.07') the member with the lowest range of a family of musical instruments\n",
      "Synset('bass.n.08') nontechnical name for any of numerous edible marine and freshwater spiny-finned fishes\n",
      "Synset('bass.s.01') having or denoting a low vocal or instrumental range\n"
     ]
    }
   ],
   "source": [
    "# wordnet is a lexicon (a little like a thesaurus)\n",
    "\n",
    "# synset represent a single definition of a word\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "for ss in wn.synsets('bass'):\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c471f127-cde6-4e99-a613-1e67b64662ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bass.n.07') the member with the lowest range of a family of musical instruments\n"
     ]
    }
   ],
   "source": [
    "# lesk is an algorithm for word sense disambiguation\n",
    "\n",
    "from nltk.wsd import lesk\n",
    "sense1 = lesk(word_tokenize(\"Sing in a lower tone, along with the bass\"), \"bass\")\n",
    "print(sense1, sense1.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a01a8c9a-eaba-4f69-892b-7dd2b2bc1478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n"
     ]
    }
   ],
   "source": [
    "sense2 = lesk(word_tokenize(\"This sea bass was really hard to catch\"), \"bass\")\n",
    "print(sense2, sense2.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd21c6-f5bf-4b3e-b726-b3a98a740c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2022.05-py39",
   "language": "python",
   "name": "conda-env-anaconda-2022.05-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
